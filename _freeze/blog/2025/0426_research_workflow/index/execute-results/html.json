{
  "hash": "95a1cfc6849a601344ad7a57def2a9f6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Research Workflow with Quarto + {targets}\ndate: 2025-04-26\nauthor: Kazuharu Yanagimoto\ncategories: [Quarto, R, Julia]\ntoc: true\nimage: img/thumbnail.png\n---\n\n\n\n# Let {targets} Take the Lead\n\n[`{targets}`](https://books.ropensci.org/targets/) is an R package for building research workflows. Its primary feature is managing R objects (data, functions, and results) and their dependencies, automatically recalculating downstream objects when upstream objects change. This allows you to maintain reproducibility throughout your research process.\n\nWhen combined with [Quarto](https://quarto.org/), you can manage all aspects of your research workflow in a single pipeline‚Äîfrom interim reports and slides to writing the final manuscript. This article explains a Quarto + {targets} research workflow I actively use in my own research. While the final pipeline is a clean and simple workflow, I also add flexibility for experimentation and iteration.\n\nThe code is available [here](https://github.com/kazuyanagimoto/quarto-research-blog/). Please refer to it for code examples and directory structure.\n\n## Workflow\n\n1. Set up initial configuration in `_targets.R`\n2. Define data cleaning in `R/tar_data.R`\n3. Configure the website in `_quarto.yml`\n4. Experiment with data analysis and models in `playground/yymmdd_*/index.qmd`\n5. Summarize interim results in slides `slide/yymmdd_*/index.qmd`\n6. Repeat steps 3-5. Incorporate key results into the pipeline via `R/tar_fact.R`, `R/tar_model.R`\n7. Write the manuscript with final results in `manuscript/*.qmd`\n\nBy the time you finish writing your manuscript, you should have a pipeline like the one below. This was generated using `targets::tar_mermaid()`.\n\n\n\n```{mermaid}\ngraph LR\n  style Graph fill:#FFFFFF00,stroke:#000000;\n  subgraph Graph\n    direction LR\n    xa60862c4ab4296bb([\"raw_accident_bike\"]):::skipped --> x034caa8952fea0bc([\"accident_bike\"]):::skipped\n    x6d55c198484f4a32([\"demand_supply_file\"]):::skipped --> xce43a680ab7f20d8([\"demand_supply\"]):::skipped\n    x6b88c7f0a7cfeae2([\"res_model\"]):::skipped --> x6d55c198484f4a32([\"demand_supply_file\"]):::skipped\n    xae87dc67ba338d4f([\"equilibrium_file\"]):::skipped --> xa24c4be63b494044([\"equilibrium\"]):::skipped\n    x6b88c7f0a7cfeae2([\"res_model\"]):::skipped --> xae87dc67ba338d4f([\"equilibrium_file\"]):::skipped\n    x02d319b13cb530b9([\"jl_file_main\"]):::skipped --> xad77b747e8ecd697([\"jl_main\"]):::skipped\n    x693460ba53a4c0cd([\"jl_file_model\"]):::skipped --> x25bf76549192ec22([\"jl_model\"]):::skipped\n    x034caa8952fea0bc([\"accident_bike\"]):::skipped --> x9470f51581cb7d73([\"logit_hospital_death\"]):::skipped\n    xce43a680ab7f20d8([\"demand_supply\"]):::skipped --> x24abe6175c545e8a([\"manuscript\"]):::skipped\n    xb033ae8b49095a26([\"num_accident\"]):::skipped --> x24abe6175c545e8a([\"manuscript\"]):::skipped\n    xa24c4be63b494044([\"equilibrium\"]):::skipped --> x24abe6175c545e8a([\"manuscript\"]):::skipped\n    x9470f51581cb7d73([\"logit_hospital_death\"]):::skipped --> x24abe6175c545e8a([\"manuscript\"]):::skipped\n    x5b3deba9281c9212([\"fns_graphics\"]):::skipped --> x24abe6175c545e8a([\"manuscript\"]):::skipped\n    x41180a2d7b7b3c28([\"parameters\"]):::skipped --> x24abe6175c545e8a([\"manuscript\"]):::skipped\n    xb033ae8b49095a26([\"num_accident\"]):::skipped --> xb7f5b6c7e9273aa9([\"manuscript_book\"]):::skipped\n    xce43a680ab7f20d8([\"demand_supply\"]):::skipped --> xb7f5b6c7e9273aa9([\"manuscript_book\"]):::skipped\n    xa24c4be63b494044([\"equilibrium\"]):::skipped --> xb7f5b6c7e9273aa9([\"manuscript_book\"]):::skipped\n    x9470f51581cb7d73([\"logit_hospital_death\"]):::skipped --> xb7f5b6c7e9273aa9([\"manuscript_book\"]):::skipped\n    x5b3deba9281c9212([\"fns_graphics\"]):::skipped --> xb7f5b6c7e9273aa9([\"manuscript_book\"]):::skipped\n    x41180a2d7b7b3c28([\"parameters\"]):::skipped --> xb7f5b6c7e9273aa9([\"manuscript_book\"]):::skipped\n    x034caa8952fea0bc([\"accident_bike\"]):::skipped --> xb033ae8b49095a26([\"num_accident\"]):::skipped\n    xfeeaf8513320133e([\"parameters_file\"]):::skipped --> x41180a2d7b7b3c28([\"parameters\"]):::skipped\n    x6b88c7f0a7cfeae2([\"res_model\"]):::skipped --> xfeeaf8513320133e([\"parameters_file\"]):::skipped\n    xee0a5a7de02f740f([\"dir_raw_accident_bike\"]):::skipped --> xa60862c4ab4296bb([\"raw_accident_bike\"]):::skipped\n    x02d319b13cb530b9([\"jl_file_main\"]):::skipped --> x6b88c7f0a7cfeae2([\"res_model\"]):::skipped\n    xad77b747e8ecd697([\"jl_main\"]):::skipped --> x6b88c7f0a7cfeae2([\"res_model\"]):::skipped\n    x25bf76549192ec22([\"jl_model\"]):::skipped --> x6b88c7f0a7cfeae2([\"res_model\"]):::skipped\n    x034caa8952fea0bc([\"accident_bike\"]):::skipped --> x5a3744590d99f661([\"website\"]):::skipped\n    x5b3deba9281c9212([\"fns_graphics\"]):::skipped --> x5a3744590d99f661([\"website\"]):::skipped\n  end\n```\n\n\n\nBefore explaining each part of the workflow, let's cover the basics of `{targets}`.\n\n## {targets} Basics\n\nThe official [tutorial](https://books.ropensci.org/targets/) is the best way to learn `{targets}` basics, but in practice, we often use the extended syntax from `{tarchetypes}`. Here, I'll explain a minimal usage based on `{tarchetypes}` syntax. This [tutorial](https://carpentries-incubator.github.io/targets-workshop/index.html) was helpful for transitioning from `{targets}` to `{tarchetypes}`.\n\n### The Three Basic Elements\n\nThe philosophy of `{targets}` divides research workflows into three elements: _files_, _functions_, and _objects_.\n\n- _Files_: Objects defined with `tar_file()` that hold file paths. They also store file size and timestamp, so even if the path hasn't changed, if the content changes, dependent parts of the pipeline will be recalculated.\n- _Objects_: Variables, data frames, and other R objects.\n- _Functions_: R functions. All inputs that the function depends on must be specified, and the output must be a file or object. This makes dependencies explicit.\n\nConceptually, you start with files, read them to create objects, and then use those objects to run functions that create new objects. These elements are defined within `tar_plan()`.\n\n```{.r}\nclean_data1 <- function(data1_raw) {\n  data1_raw |>\n    filter(!is.na(col1))\n}\n\ntar_plan(\n  tar_file(data1_raw_file, \"path/to/file/data1.csv\"),\n  data1_raw = readr::read_csv(data1_raw_file),\n  data1_cleaned = clean_data1(data1_raw),\n)\n```\n\nIn the example above, `data1_raw_file` is a file, `data1_raw` and `data1_cleaned` are objects, and `readr::read_csv` and `clean_data1()` are functions.\n\n### Execution and Dependency Management\n\nYou can visualize your defined pipeline with `targets::tar_visnetwork()`.\n\n![](img/step0.png){width=80% fig-align=\"center\"}\n\nHere, triangles represent functions, and circles represent files and objects. The light blue color indicates parts of the pipeline that haven't been executed yet. When you run `targets::tar_make()`:\n\n![](img/step1.png){width=80% fig-align=\"center\"}\n\nSuccessfully executed parts turn gray. If you change the contents of `data1.csv` (`data1_raw_file`):\n\n![](img/step2-1.png){width=80% fig-align=\"center\"}\n\nParts with dependencies return to the unexecuted state. Of course, running `targets::tar_make()` again will recalculate the dependent parts:\n\n![](img/step1.png){width=80% fig-align=\"center\"}\n\nSimilarly, if you change the contents of the `clean_data1()` function:\n\n![](img/step2-2.png){width=80% fig-align=\"center\"}\n\nThis is the basic workflow of `{targets}`: define pipelines in `tar_plan()`, then execute them with `tar_make()`.\n\n# Quarto + {targets} Workflow\n\n## 1. Initial Configuration in `_targets.R`\n\n```{.r filename=\"_targets.R\"}\nlibrary(targets)\nlibrary(tarchetypes)\nsuppressPackageStartupMessages(library(dplyr))\n\noptions(\n  tidyverse.quiet = TRUE,\n  dplyr.summarise.inform = FALSE,\n  readr.show_col_types = FALSE\n)\n\n# here::here() returns an absolute path, which then gets stored in tar_meta and\n# becomes computer-specific (i.e. /Users/andrew/Research/blah/thing.Rmd).\n# There's no way to get a relative path directly out of here::here(), but\n# fs::path_rel() works fine with it (see\n# https://github.com/r-lib/here/issues/36#issuecomment-530894167)\nhere_rel <- function(...) {\n  fs::path_rel(here::here(...))\n}\n\ntar_source()\n\n#-------------------------------------------------------------------------------\n# Main Pipeline\n#-------------------------------------------------------------------------------\n\ntar_plan(\n  # Data Preparation ----------\n  data,\n  # Analysis ------------------\n  fact,\n  model,\n  # Graphics ------------------\n  fns_graphics = lst(theme_proj, color_base, color_accent, scale_fill_gender),\n  # Manuscript ----------------\n  tar_quarto(manuscript_book, path = \"manuscript\", quiet = FALSE),\n  tar_quarto(manuscript, path = \"manuscript/main.qmd\", quiet = FALSE),\n  # Website -------------------\n  tar_quarto(\n    website,\n    path = \".\",\n    quiet = FALSE,\n    extra_files = here_rel(\"manuscript\", \"main.pdf\")\n  )\n)\n```\n\nThe three crucial parts are:\n\n### `tar_source()`\n\nSpecifies the directory containing source code for functions used in your pipeline. By default, the `R/` directory is specified.\n\n### `tar_plan()`\n\nDefines the pipeline. You don't need to include every pipeline element here‚Äîyou can define pipelines in files loaded via `tar_source()` and call them. For example, the `data` pipeline is defined in `R/tar_data.R`:\n\n\n\n::: {.cell filename='R/tar_data.R'}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R/tar_data.R\"}\ndata <- tar_plan(\n  dir_raw_accident_bike = download_accident_bike(here_rel(\n    \"data\",\n    \"accident_bike\"\n  )),\n  raw_accident_bike = load_accident_bike(dir_raw_accident_bike),\n  accident_bike = clean_accident_bike(raw_accident_bike)\n)\n\ndownload_accident_bike <- function(dir_file) {\n  url_base <- \"https://datos.madrid.es/egob/catalogo/300228-%s-accidentes-trafico-detalle.csv\"\n\n  years <- 2019:2023\n  keys <- c(19, 21, 22, 24, 26) #URL becomes caos since 2020\n\n  if (!dir.exists(dir_file)) {\n    dir.create(dir_file)\n  }\n\n  tibble(\n    year = 2019:2023,\n    key = c(19, 21, 22, 24, 26)\n  ) |>\n    purrr::pwalk(\\(year, key) {\n      url <- sprintf(url_base, key)\n      download.file(url, destfile = file.path(dir_file, paste0(year, \".txt\")))\n    })\n  return(dir_file)\n}\n\nload_accident_bike <- function(dir_raw_accident_bike) {\n  purrr::map(\n    2019:2023,\n    ~ readr::read_delim(\n      file.path(dir_raw_accident_bike, paste0(.x, \".txt\")),\n      delim = \";\"\n    )\n  ) |>\n    bind_rows()\n}\n\nclean_accident_bike <- function(raw_accident_bike) {\n  raw_accident_bike |>\n    rename(\n      id = num_expediente,\n      date = fecha,\n      hms = hora,\n      street = localizacion,\n      num_street = numero,\n      code_district = cod_distrito,\n      district = distrito,\n      type_accident = tipo_accidente,\n      weather = estado_meteorol√≥gico,\n      type_vehicle = tipo_vehiculo,\n      type_person = tipo_persona,\n      age_c = rango_edad,\n      gender = sexo,\n      code_injury8 = cod_lesividad,\n      injury8 = lesividad,\n      coord_x = coordenada_x_utm,\n      coord_y = coordenada_y_utm,\n      positive_alcohol = positiva_alcohol,\n      positive_drug = positiva_droga\n    ) |>\n    mutate(\n      time = lubridate::dmy_hms(paste0(date, hms), tz = \"Europe/Madrid\"),\n      district = na_if(district, \"NULL\"),\n      district = stringr::str_to_title(district),\n      weather = recode_factor(\n        weather,\n        \"Despejado\" = \"sunny\",\n        \"Nublado\" = \"cloud\",\n        \"Lluvia d√©bil\" = \"soft rain\",\n        \"Lluvia intensa\" = \"hard rain\",\n        \"LLuvia intensa\" = \"hard rain\",\n        \"Nevando\" = \"snow\",\n        \"Granizando\" = \"hail\",\n        \"Se desconoce\" = NULL,\n        \"NULL\" = NULL\n      ),\n      type_person = recode_factor(\n        type_person,\n        \"Conductor\" = \"Driver\",\n        \"Pasajero\" = \"Passenger\",\n        \"Peat√≥n\" = \"Pedestrian\",\n        \"NULL\" = NULL\n      ),\n      age_c = recode_factor(\n        age_c,\n        \"Menor de 5 a√±os\" = \"<5\",\n        \"De 6 a 9 a√±os\" = \"6-9\",\n        \"De 10 a 14 a√±os\" = \"10-14\",\n        \"De 15 a 17 a√±os\" = \"15-17\",\n        \"De 18 a 20 a√±os\" = \"18-20\",\n        \"De 21 a 24 a√±os\" = \"21-24\",\n        \"De 25 a 29 a√±os\" = \"25-29\",\n        \"De 30 a 34 a√±os\" = \"30-34\",\n        \"De 35 a 39 a√±os\" = \"35-39\",\n        \"De 40 a 44 a√±os\" = \"40-44\",\n        \"De 45 a 49 a√±os\" = \"45-49\",\n        \"De 50 a 54 a√±os\" = \"50-54\",\n        \"De 55 a 59 a√±os\" = \"55-59\",\n        \"De 60 a 64 a√±os\" = \"60-64\",\n        \"De 65 a 69 a√±os\" = \"65-69\",\n        \"De 70 a 74 a√±os\" = \"70-74\",\n        \"M√°s de 74 a√±os\" = \">74\",\n        \"Desconocido\" = NULL\n      ),\n      gender = recode_factor(\n        gender,\n        \"Hombre\" = \"Men\",\n        \"Mujer\" = \"Women\",\n        \"Desconocido\" = NULL\n      ),\n      injury8 = recode_factor(\n        injury8,\n        \"Sin asistencia sanitaria\" = \"No health care\",\n        \"Asistencia sanitaria s√≥lo en el lugar del accidente\" = \"Healthcare only at the place of the accident\",\n        \"Asistencia sanitaria ambulatoria con posterioridad\" = \"Subsequent outpatient health care\",\n        \"Asistencia sanitaria inmediata en centro de salud o mutua\" = \"Immediate health care at a health center\",\n        \"Atenci√≥n en urgencias sin posterior ingreso\" = \"Emergency care without subsequent hospitalization\",\n        \"Ingreso superior a 24 horas\" = \"Hospitalization after 24 hours\",\n        \"Ingreso inferior o igual a 24 horas\" = \"Hospitalization within 24 hours\",\n        \"Fallecido 24 horas\" = \"Died within 24 hours\",\n        \"Se desconoce\" = NULL,\n        \"NULL\" = NULL\n      ),\n      positive_alcohol = positive_alcohol == \"S\",\n      positive_drug = positive_drug == \"S\",\n      is_died = injury8 == \"Died within 24 hours\",\n      is_hospitalized = injury8 %in%\n        c(\n          \"Hospitalization after 24 hours\",\n          \"Hospitalization within 24 hours\",\n          \"Died within 24 hours\"\n        )\n    ) |>\n    filter(!is.na(type_person), !is.na(gender))\n}\n```\n:::\n\n\n\n### `here_rel()`\n\n`here::here()` is a function for specifying relative paths based on the project root directory. This ensures you don't need to change paths if the project root directory changes. However, using `here::here()` within `_targets.R` saves absolute paths, which causes problems when sharing with others. Therefore, we use a function that maintains the convenience of `here::here()` while saving relative paths. This part is based on Dr. Andrew Heiss's [code](https://github.com/andrewheiss/lemon-lucifer/blob/main/_targets.R).\n\n## 2. Define Data Cleaning\n\nDefine your data cleaning pipeline. See the code here for details:\n\n\n\n::: {.cell filename='R/tar_data.R'}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R/tar_data.R\"}\ndata <- tar_plan(\n  dir_raw_accident_bike = download_accident_bike(here_rel(\n    \"data\",\n    \"accident_bike\"\n  )),\n  raw_accident_bike = load_accident_bike(dir_raw_accident_bike),\n  accident_bike = clean_accident_bike(raw_accident_bike)\n)\n\ndownload_accident_bike <- function(dir_file) {\n  url_base <- \"https://datos.madrid.es/egob/catalogo/300228-%s-accidentes-trafico-detalle.csv\"\n\n  years <- 2019:2023\n  keys <- c(19, 21, 22, 24, 26) #URL becomes caos since 2020\n\n  if (!dir.exists(dir_file)) {\n    dir.create(dir_file)\n  }\n\n  tibble(\n    year = 2019:2023,\n    key = c(19, 21, 22, 24, 26)\n  ) |>\n    purrr::pwalk(\\(year, key) {\n      url <- sprintf(url_base, key)\n      download.file(url, destfile = file.path(dir_file, paste0(year, \".txt\")))\n    })\n  return(dir_file)\n}\n\nload_accident_bike <- function(dir_raw_accident_bike) {\n  purrr::map(\n    2019:2023,\n    ~ readr::read_delim(\n      file.path(dir_raw_accident_bike, paste0(.x, \".txt\")),\n      delim = \";\"\n    )\n  ) |>\n    bind_rows()\n}\n\nclean_accident_bike <- function(raw_accident_bike) {\n  raw_accident_bike |>\n    rename(\n      id = num_expediente,\n      date = fecha,\n      hms = hora,\n      street = localizacion,\n      num_street = numero,\n      code_district = cod_distrito,\n      district = distrito,\n      type_accident = tipo_accidente,\n      weather = estado_meteorol√≥gico,\n      type_vehicle = tipo_vehiculo,\n      type_person = tipo_persona,\n      age_c = rango_edad,\n      gender = sexo,\n      code_injury8 = cod_lesividad,\n      injury8 = lesividad,\n      coord_x = coordenada_x_utm,\n      coord_y = coordenada_y_utm,\n      positive_alcohol = positiva_alcohol,\n      positive_drug = positiva_droga\n    ) |>\n    mutate(\n      time = lubridate::dmy_hms(paste0(date, hms), tz = \"Europe/Madrid\"),\n      district = na_if(district, \"NULL\"),\n      district = stringr::str_to_title(district),\n      weather = recode_factor(\n        weather,\n        \"Despejado\" = \"sunny\",\n        \"Nublado\" = \"cloud\",\n        \"Lluvia d√©bil\" = \"soft rain\",\n        \"Lluvia intensa\" = \"hard rain\",\n        \"LLuvia intensa\" = \"hard rain\",\n        \"Nevando\" = \"snow\",\n        \"Granizando\" = \"hail\",\n        \"Se desconoce\" = NULL,\n        \"NULL\" = NULL\n      ),\n      type_person = recode_factor(\n        type_person,\n        \"Conductor\" = \"Driver\",\n        \"Pasajero\" = \"Passenger\",\n        \"Peat√≥n\" = \"Pedestrian\",\n        \"NULL\" = NULL\n      ),\n      age_c = recode_factor(\n        age_c,\n        \"Menor de 5 a√±os\" = \"<5\",\n        \"De 6 a 9 a√±os\" = \"6-9\",\n        \"De 10 a 14 a√±os\" = \"10-14\",\n        \"De 15 a 17 a√±os\" = \"15-17\",\n        \"De 18 a 20 a√±os\" = \"18-20\",\n        \"De 21 a 24 a√±os\" = \"21-24\",\n        \"De 25 a 29 a√±os\" = \"25-29\",\n        \"De 30 a 34 a√±os\" = \"30-34\",\n        \"De 35 a 39 a√±os\" = \"35-39\",\n        \"De 40 a 44 a√±os\" = \"40-44\",\n        \"De 45 a 49 a√±os\" = \"45-49\",\n        \"De 50 a 54 a√±os\" = \"50-54\",\n        \"De 55 a 59 a√±os\" = \"55-59\",\n        \"De 60 a 64 a√±os\" = \"60-64\",\n        \"De 65 a 69 a√±os\" = \"65-69\",\n        \"De 70 a 74 a√±os\" = \"70-74\",\n        \"M√°s de 74 a√±os\" = \">74\",\n        \"Desconocido\" = NULL\n      ),\n      gender = recode_factor(\n        gender,\n        \"Hombre\" = \"Men\",\n        \"Mujer\" = \"Women\",\n        \"Desconocido\" = NULL\n      ),\n      injury8 = recode_factor(\n        injury8,\n        \"Sin asistencia sanitaria\" = \"No health care\",\n        \"Asistencia sanitaria s√≥lo en el lugar del accidente\" = \"Healthcare only at the place of the accident\",\n        \"Asistencia sanitaria ambulatoria con posterioridad\" = \"Subsequent outpatient health care\",\n        \"Asistencia sanitaria inmediata en centro de salud o mutua\" = \"Immediate health care at a health center\",\n        \"Atenci√≥n en urgencias sin posterior ingreso\" = \"Emergency care without subsequent hospitalization\",\n        \"Ingreso superior a 24 horas\" = \"Hospitalization after 24 hours\",\n        \"Ingreso inferior o igual a 24 horas\" = \"Hospitalization within 24 hours\",\n        \"Fallecido 24 horas\" = \"Died within 24 hours\",\n        \"Se desconoce\" = NULL,\n        \"NULL\" = NULL\n      ),\n      positive_alcohol = positive_alcohol == \"S\",\n      positive_drug = positive_drug == \"S\",\n      is_died = injury8 == \"Died within 24 hours\",\n      is_hospitalized = injury8 %in%\n        c(\n          \"Hospitalization after 24 hours\",\n          \"Hospitalization within 24 hours\",\n          \"Died within 24 hours\"\n        )\n    ) |>\n    filter(!is.na(type_person), !is.na(gender))\n}\n```\n:::\n\n\n\nThe key points are:\n\n1. Define raw data files with `tar_file()`\n1. Read raw data using functions like `readr::read_csv()`\n1. Create cleaning functions that take raw data as arguments and return cleaned data\n\nYou can also combine the first two steps by `tar_file_read()`:\n\n```{.r}\ntar_plan(\n  tar_file_read(\n    data1_raw,\n    here_rel(\"path\", \"to\", \"file\", \"data1.csv\"),\n    readr::read_csv(!!.x),\n  ),\n  data1_cleaned = clean_data1(data1_raw)\n)\n```\n\nTo download online files and define them with `tar_file`:\n\n```{.r}\ndownload_file <- function(url, destfile) {\n  if (!file.exists(destfile)) {\n    download.file(url, destfile)\n  }\n  return(destfile)\n}\n```\n\nDefine this function and call it within `tar_file()`. The key is to return the path to the saved file.\n\nFor your information, I have outlined my approach to data cleaning in this [workshop](https://github.com/kazuyanagimoto/workshop-r-2022).\n\n## 3. Configure the Website\n\nUse `tar_quarto()` to build a website within your pipeline. For the purpose of websites and specific configurations, see my blog post on [\"Researching as if to Blog\"](https://kazuyanagimoto.com/blog/2024/04/05/).\n\n## 4. Experiment with Data Analysis and Models\n\nCreate notebook-style posts in the `playground` directory of your website to experiment with data analysis and models.\n\nYou can load cleaned data with `tar_load()`. I define figure settings in `R/fns_graphics.R` and import them when needed:\n\n\n````{.markdown filename=\"posts/240324_accident_bike/index.qmd\"}\n```{{r}}\n#| label: setup\n#| include: false\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(fixest)\nlibrary(tinytable)\nlibrary(modelsummary)\n\ntargets::tar_config_set(\n  store = here::here(\"_targets\"),\n  script = here::here(\"_targets.R\")\n)\n\ntargets::tar_load(c(accident_bike))\ninvisible(list2env(targets::tar_read(fns_graphics), .GlobalEnv))\n\ntheme_set(theme_proj())\n```\n````\n\nThe key is to avoid over-incorporating experiments into your pipeline. Most analyses in the experimental stage won't make it into the final paper. Including them in the pipeline makes dependency management unnecessarily complex. Instead, experiment in the `playground` directory and only incorporate essential elements into the pipeline.\n\nBy combining `tar_quarto()` with Quarto's `freeze: auto` setting, results are not recomputed unless you manually compile them. While this means that dependent parts won't recalculate when upstream changes occur, it has the benefit of minimal management for unnecessary parts. If upstream changes do occur, you can manually recompile only the necessary parts of the project.\n\n## 5. Summarize Interim Results in Slides\n\nDuring research, you'll often present interim results. It's good practice to compile important findings from your experiments into slides. Like the experimental phase, this doesn't need to be incorporated into the pipeline. In this project, the `slide` directory is compiled as part of the website.\n\nI create slides using [Quarto Clean Theme](https://github.com/kazuyanagimoto/quarto-clean-typst). Since they're created with Quarto, they integrate naturally into this workflow. Additionally, using Typst allows for faster compilation than Beamer. You can see the [demo](https://kazuyanagimoto.com/quarto-clean-typst/template-full.pdf) for details.\n\n\n## 6. Repeat Steps 3-5 and Incorporate Key Results into the Pipeline\n\nContinue your research, getting feedback from presentations. When you have sufficient results for your manuscript, proceed to the next step. This is where you define pipelines in files like `R/tar_fact.R` and `R/tar_model.R`.\n\n### Incorporate Key Results into the Pipeline\n\n\n\n::: {.cell filename='R/tar_fact.R'}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R/tar_fact.R\"}\nfact <- tar_plan(\n  num_accident = compute_num_accident(accident_bike),\n  logit_hospital_death = compute_logit_hospital_death(accident_bike)\n)\n\ncompute_num_accident <- function(accident_bike) {\n  accident_bike |>\n    summarize(n = n(), .by = c(type_person, gender))\n}\n\ncompute_logit_hospital_death <- function(accident_bike) {\n  list(\n    \"(1)\" = fixest::feglm(\n      is_hospitalized ~\n        type_person + positive_alcohol + positive_drug | age_c + gender,\n      family = binomial(logit),\n      data = accident_bike\n    ),\n    \"(2)\" = fixest::feglm(\n      is_hospitalized ~\n        type_person +\n          positive_alcohol +\n          positive_drug |\n          age_c + gender + type_vehicle,\n      family = binomial(logit),\n      data = accident_bike\n    ),\n    \"(3)\" = fixest::feglm(\n      is_hospitalized ~\n        type_person +\n          positive_alcohol +\n          positive_drug |\n          age_c + gender + type_vehicle + weather,\n      family = binomial(logit),\n      data = accident_bike\n    ),\n    \"(4)\" = fixest::feglm(\n      is_died ~ type_person + positive_alcohol + positive_drug | age_c + gender,\n      family = binomial(logit),\n      data = accident_bike\n    ),\n    \"(5)\" = fixest::feglm(\n      is_died ~\n        type_person +\n          positive_alcohol +\n          positive_drug |\n          age_c + gender + type_vehicle,\n      family = binomial(logit),\n      data = accident_bike\n    ),\n    \"(6)\" = fixest::feglm(\n      is_died ~\n        type_person +\n          positive_alcohol +\n          positive_drug |\n          age_c + gender + type_vehicle + weather,\n      family = binomial(logit),\n      data = accident_bike\n    )\n  )\n}\n```\n:::\n\n\n\nIncorporate figures needed for your paper into the pipeline. I define functions like `compute_*()` that take cleaned data as arguments and return calculated results as numbers or data frames. I don't create figures here‚ÄîI do that within the manuscript.\n\nFor LaTeX users, you might want to save figures at this stage. For example:\n\n```{.r}\ntar_plan(\n  tar_file(\n    fig1_file,\n    plot_fig1(data1, here_rel(\"path\", \"to\", \"file\", \"fig1.pdf\"))\n  )\n)\n\nplot_fig1 <- function(data1, path_fig1) {\n  ggplot(data1, aes(x = col1, y = col2)) +\n    geom_point()\n  \n  ggsave(path_fig1)\n  return(path_fig1)\n}\n```\n\n### Incorporate Julia Code into the Pipeline\n\nWhile R analyses can be directly incorporated into the pipeline, Julia code requires some extra steps. Here's my approach:\n\n1. Load Julia source code files with `tar_file_read()` and incorporate them as `jl_file_*`\n2. Execute Julia code from R using `system2()` via the `run_model()` function\n3. Save Julia execution results as CSV or YAML files for loading in R with `tar_file_read()`\n\n\n\n::: {.cell filename='R/tar_model.R'}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R/tar_model.R\"}\nmodel <- tar_plan(\n  tar_map(\n    values = list(name = c(\"main\", \"model\")),\n    names = name,\n    tar_file_read(\n      jl,\n      here_rel(\"Julia\", paste0(name, \".jl\")),\n      readLines(!!.x)\n    )\n  ),\n  res_model = run_model(jl_file_main, jl_main, jl_model),\n  tar_file_read(\n    parameters,\n    res_model[[1]],\n    yaml::read_yaml(!!.x)\n  ),\n  tar_file_read(\n    demand_supply,\n    res_model[[2]],\n    read.csv(!!.x)\n  ),\n  tar_file_read(\n    equilibrium,\n    res_model[[3]],\n    yaml::read_yaml(!!.x)\n  )\n)\n\nrun_model <- function(jl_file_main, ...) {\n  system2(command = \"julia\", args = c(\"--project=.\", jl_file_main))\n\n  return(file.path(\n    here_rel(\"output\", \"Julia\"),\n    c(\"parameters.yaml\", \"demand_supply.csv\", \"equilibrium.yaml\")\n  ))\n}\n```\n:::\n\n\n\nThe key points are:\n\n1. Specify all dependencies in `run_model()` arguments to include Julia dependencies\n2. Group saved result files into a list and load them one by one from R\n\nWhen executing with `system2()`, Julia's path might not be accessible (due to differences between your PC's default shell and R's shell). In that case, define Julia's path in `.Renviron`:\n\n```{.bash filename=\".Renviron\"}\nPATH_JULIA=/path/to/julia/\n```\n\nAnd load it in `.Rprofile`:\n\n```{.r filename=\".Rprofile\"}\nsource(\"renv/activate.R\")\nSys.setenv(\n  PATH = paste(Sys.getenv(\"PATH_JULIA\"), Sys.getenv(\"PATH\"), sep = \":\")\n)\n```\n\n## 7. Write the Manuscript with Final Results\n\nWrite your manuscript in the `manuscript` directory. Here, load the pipeline execution results with `tar_load()`. I use these three steps:\n\n1. Configure the directory as a [Quarto Book](https://quarto.org/docs/books/) in `manuscript/_quarto.yml`\n2. Write the Quarto Book as `01-intro.qmd`, etc.\n3. Combine `01-intro.qmd`, `02-methods.qmd`, etc. in `manuscript/main.qmd` (using `{{< include **-**.qmd >}}`) and compile\n\n### Why Write as a Quarto Book?\n\nWriting as a Quarto Book enables cross-references across multiple files. This is very convenient‚Äîdividing your manuscript into files by section makes the structure easier to grasp, and cross-reference auto-completion makes writing smoother.\n\nHowever, the Quarto Book output format isn't ideal for papers, so I combine these files and compile them in `manuscript/main.qmd`:\n\n```{.md filename=\"manuscript/main.qmd\"}\n{{{< include 01-intro.qmd >}}}\n{{{< include 02-fact.qmd >}}}\n{{{< include 03-model.qmd >}}}\n{{{< include 04-result.qmd >}}}\n{{{< include 05-conclusion.qmd >}}}\n\n{{{< appendix >}}}\n\n{{{< include 11-data.qmd >}}}\n\n{{{< pagebreak >}}}\n\n:::{#refs}\n:::\n```\n\nI use Typst as the backend for fast compilation and the [quarto-academic-typst](https://github.com/kazuyanagimoto/quarto-academic-typst) template. If you need LaTeX source code, you can generate it with `quarto::quarto_render()` (I used this for my doctoral thesis to match the LaTeX template).\n\n### For LaTeX Users\n\nIf you're writing in LaTeX and compiling with `TinyTeX`, you can incorporate it into the pipeline. For example:\n\n```{.r}\ntar_plan(\n  tar_file_read(\n    manuscript,\n    here_rel(\"manuscript\", \"main.tex\"),\n    readLines(!!.x)\n  ),\n  tar_file(\n    manuscript_pdf,\n    compile_latex(manuscript, here_rel(\"manuscript\", \"main.pdf\"))\n  )\n)\n\ncompile_latex <- function(manuscript_file, path_pdf) {\n  tinytex::xelatex(\n    manuscript_file,\n    output = path_pdf\n    pdf_file = path_pdf\n  )\n  return(path_pdf)\n}\n```\n\nNote that you may need to include all figure and table dependencies.\n\n# Conclusion\n\nI've explained a research workflow using Quarto + `{targets}`. While `{targets}` might be somewhat challenging at first, trusting in it and maintaining an executable state will help you maintain reproducibility. Ultimately, this should help you conduct your research more efficiently.\n\nHappy Quarto + {targets} Life! ü•Ç\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}